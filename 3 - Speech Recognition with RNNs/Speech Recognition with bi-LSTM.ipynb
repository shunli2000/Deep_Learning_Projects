{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4qfYrVoO4v"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:28:02.723260Z",
     "iopub.status.busy": "2024-11-07T05:28:02.722741Z",
     "iopub.status.idle": "2024-11-07T05:29:51.597574Z",
     "shell.execute_reply": "2024-11-07T05:29:51.596135Z",
     "shell.execute_reply.started": "2024-11-07T05:28:02.723226Z"
    },
    "id": "mA9qZoIDcx-h",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONgAWhqdoYy-"
   },
   "source": [
    "\n",
    "This may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:29:51.600783Z",
     "iopub.status.busy": "2024-11-07T05:29:51.600294Z",
     "iopub.status.idle": "2024-11-07T05:32:46.442578Z",
     "shell.execute_reply": "2024-11-07T05:32:46.441372Z",
     "shell.execute_reply.started": "2024-11-07T05:29:51.600723Z"
    },
    "id": "SS7a7xeEoaV9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ctcdecode'...\n",
      "remote: Enumerating objects: 1102, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1102/1102), 782.27 KiB | 12.42 MiB/s, done.\n",
      "Resolving deltas: 100% (529/529), done.\n",
      "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
      "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
      "Cloning into '/kaggle/working/ctcdecode/third_party/ThreadPool'...\n",
      "remote: Enumerating objects: 82, done.        \n",
      "remote: Counting objects: 100% (26/26), done.        \n",
      "remote: Compressing objects: 100% (9/9), done.        \n",
      "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56 (from 1)        \n",
      "Receiving objects: 100% (82/82), 13.34 KiB | 3.34 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n",
      "Cloning into '/kaggle/working/ctcdecode/third_party/kenlm'...\n",
      "remote: Enumerating objects: 14170, done.        \n",
      "remote: Counting objects: 100% (483/483), done.        \n",
      "remote: Compressing objects: 100% (337/337), done.        \n",
      "remote: Total 14170 (delta 167), reused 410 (delta 132), pack-reused 13687 (from 1)        \n",
      "Receiving objects: 100% (14170/14170), 5.91 MiB | 20.66 MiB/s, done.\n",
      "Resolving deltas: 100% (8047/8047), done.\n",
      "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
      "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (70.0.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (21.3)\n",
      "Collecting packaging\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools, packaging\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 70.0.0\n",
      "    Uninstalling setuptools-70.0.0:\n",
      "      Successfully uninstalled setuptools-70.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed packaging-24.1 setuptools-75.3.0\n",
      "/kaggle/working/ctcdecode\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchsummaryx==1.1.0\n",
    "!pip install wandb --quiet\n",
    "!pip install python-Levenshtein -q\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget -q\n",
    "!pip install --upgrade setuptools packaging\n",
    "%cd ctcdecode\n",
    "!pip install . -q\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWVONJxCobPc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:46.445357Z",
     "iopub.status.busy": "2024-11-07T05:32:46.444929Z",
     "iopub.status.idle": "2024-11-07T05:32:49.142170Z",
     "shell.execute_reply": "2024-11-07T05:32:49.141185Z",
     "shell.execute_reply.started": "2024-11-07T05:32:46.445309Z"
    },
    "id": "78ZTCIXoof2f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchaudio.transforms as tat\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# imports for decoding and distance calculation\n",
    "import Levenshtein\n",
    "import ctcdecode\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORNHnSFroP0"
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.145684Z",
     "iopub.status.busy": "2024-11-07T05:32:49.144866Z",
     "iopub.status.idle": "2024-11-07T05:32:49.154721Z",
     "shell.execute_reply": "2024-11-07T05:32:49.153892Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.145647Z"
    },
    "id": "k0v7wHRWrqH6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ARPABET PHONEME MAPPING\n",
    "# DO NOT CHANGE\n",
    "\n",
    "CMUdict_ARPAbet = {\n",
    "    \"\" : \" \",\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
    "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
    "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
    "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
    "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
    "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
    "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
    "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
    "}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "\n",
    "PHONEMES = CMUdict[:-2]\n",
    "LABELS = ARPAbet[:-2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.156402Z",
     "iopub.status.busy": "2024-11-07T05:32:49.156033Z",
     "iopub.status.idle": "2024-11-07T05:32:49.166619Z",
     "shell.execute_reply": "2024-11-07T05:32:49.165814Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.156361Z"
    },
    "id": "eN2kcxwXLLBb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# You might want to play around with the mapping as a sanity check here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agmNBKf4JrLV"
   },
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.168157Z",
     "iopub.status.busy": "2024-11-07T05:32:49.167717Z",
     "iopub.status.idle": "2024-11-07T05:32:49.180119Z",
     "shell.execute_reply": "2024-11-07T05:32:49.179266Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.168115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "class PermuteBlock(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "audio_transforms = nn.Sequential(\n",
    "    PermuteBlock(), \n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=5),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100),\n",
    "    PermuteBlock()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.181843Z",
     "iopub.status.busy": "2024-11-07T05:32:49.181573Z",
     "iopub.status.idle": "2024-11-07T05:32:49.200588Z",
     "shell.execute_reply": "2024-11-07T05:32:49.199690Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.181815Z"
    },
    "id": "afd0_vlbJmr_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # For this homework, we give you full flexibility to design your data set class.\n",
    "    # Hint: The data from HW1 is very similar to this HW\n",
    "\n",
    "    #TODO\n",
    "    def __init__(self, root, phonemes = PHONEMES,context=0, partition= \"train-clean-100\",audio_transformation=None): # Feel free to add more arguments\n",
    "\n",
    "        self.context    = context\n",
    "        self.phonemes   = phonemes\n",
    "        self.transformation = audio_transformation\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "\n",
    "        # Load the directory and all files in them\n",
    "\n",
    "        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n",
    "        self.transcript_dir = os.path.join(root, partition, 'transcript')\n",
    "\n",
    "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
    "        self.transcript_files = sorted(os.listdir(self.transcript_dir))\n",
    "\n",
    "        self.PHONEMES = PHONEMES\n",
    "        \n",
    "         # Making sure that we have the same no. of mfcc and transcripts\n",
    "        assert len(self.mfcc_files) == len(self.transcript_files)\n",
    "\n",
    "        #TODO\n",
    "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
    "        self.length = len(self.mfcc_files)\n",
    "\n",
    "        #TODO\n",
    "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
    "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
    "\n",
    "        #TODO\n",
    "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
    "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
    "        '''\n",
    "        You may decide to do this in __getitem__ if you wish.\n",
    "        However, doing this here will make the __init__ function take the load of\n",
    "        loading the data, and shift it away from training.\n",
    "        '''\n",
    "        self.mfccs, self.transcripts = [], []\n",
    "        \n",
    "        for i in range(len(self.mfcc_files)):\n",
    "        #   Load a single mfcc\n",
    "            mfcc        = np.load(os.path.join(self.mfcc_dir, self.mfcc_files[i]))\n",
    "        #   Do Cepstral Normalization of mfcc (explained in writeup)\n",
    "            mfcc = (mfcc - np.mean(mfcc, axis=0)) / np.std(mfcc, axis=0)\n",
    "        #   Load the corresponding transcript\n",
    "            transcript  = np.load(os.path.join(self.transcript_dir, self.transcript_files[i]))\n",
    "            if transcript[0] == \"[SOS]\" and transcript[-1] == \"[EOS]\":\n",
    "                transcript = transcript[1:-1]\n",
    "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
    "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
    "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
    "            transcript = np.vectorize(self.phonemes.index)(transcript)\n",
    "        \n",
    "            self.mfccs.append(mfcc)\n",
    "            self.transcripts.append(transcript)\n",
    "            \n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        '''\n",
    "        TODO: What do we return here?\n",
    "        '''\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
    "\n",
    "        If you didn't do the loading and processing of the data in __init__,\n",
    "        do that here.\n",
    "\n",
    "        Once done, return a tuple of features and labels.\n",
    "        '''\n",
    "\n",
    "        mfcc = torch.FloatTensor(self.mfccs[ind])\n",
    "        transcript = torch.tensor(self.transcripts[ind])\n",
    "        return mfcc, transcript\n",
    "\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        '''\n",
    "        TODO:\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "            and lengths of labels.\n",
    "        '''                            \n",
    "\n",
    "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
    "        # Also be sure to check the input format (batch_first)\n",
    "        batch_mfcc, batch_transcript = [], []\n",
    "        lengths_mfcc, lengths_transcript = [], []\n",
    "        for (m, t) in batch:\n",
    "            batch_mfcc.append(m)\n",
    "            lengths_mfcc.append(len(m))\n",
    "            batch_transcript.append(t)\n",
    "            lengths_transcript.append(len(t))\n",
    "        \n",
    "       \n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first = True)\n",
    "        \n",
    "        if self.transformation is not None:\n",
    "            batch_mfcc_pad = self.transformation(batch_mfcc_pad)\n",
    "        \n",
    "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first = True)\n",
    "\n",
    "\n",
    "\n",
    "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "        #                  -> Would we apply transformation on the validation set as well?\n",
    "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "\n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqDrxeHfJw4g"
   },
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.202261Z",
     "iopub.status.busy": "2024-11-07T05:32:49.201949Z",
     "iopub.status.idle": "2024-11-07T05:32:49.216328Z",
     "shell.execute_reply": "2024-11-07T05:32:49.215506Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.202229Z"
    },
    "id": "HrLS1wfVJppA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test Dataloader\n",
    "#TODO\n",
    "class AudioDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, phonemes = PHONEMES,context=0, partition= \"test-clean\"): # Feel free to add more arguments\n",
    "\n",
    "        self.context    = context\n",
    "        self.phonemes   = phonemes\n",
    "\n",
    "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
    "        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n",
    "        # TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
    "        self.mfcc_files   = sorted(os.listdir(self.mfcc_dir))\n",
    "\n",
    "\n",
    "        self.length = len(self.mfcc_files)\n",
    "\n",
    "        self.mfccs, self.transcripts = [], []\n",
    "\n",
    "        for i in range(len(self.mfcc_files)):\n",
    "                  #   Load a single mfcc\n",
    "            mfcc = np.load(os.path.join(self.mfcc_dir, self.mfcc_files[i]))\n",
    "            mfcc = (mfcc - np.mean(mfcc, axis=0)) / np.std(mfcc, axis=0)\n",
    "\n",
    "            self.mfccs.append(mfcc)\n",
    "            \n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        '''\n",
    "        TODO: What do we return here?\n",
    "        '''\n",
    "        return self.length\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        mfcc = self.mfccs[ind]\n",
    "        return torch.FloatTensor(mfcc)\n",
    "      \n",
    "    def collate_fn(self, batch):\n",
    "        batch_mfcc = []\n",
    "        lengths_mfcc = []\n",
    "        \n",
    "        for mfcc in batch:\n",
    "            batch_mfcc.append(mfcc)   \n",
    "            lengths_mfcc.append(len(mfcc))\n",
    "      \n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first = True)\n",
    "            \n",
    "\n",
    "            # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "            # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "            #                  -> Would we apply transformation on the validation set as well?\n",
    "            #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "            \n",
    "            # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt-veYcdL6Fe"
   },
   "source": [
    "### Config - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.218220Z",
     "iopub.status.busy": "2024-11-07T05:32:49.217578Z",
     "iopub.status.idle": "2024-11-07T05:32:49.229856Z",
     "shell.execute_reply": "2024-11-07T05:32:49.228995Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.218177Z"
    },
    "id": "MN82c3KpLup8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feel free to add more items here\n",
    "config = {\n",
    "    \"beam_width\" : 1,\n",
    "    \"lr\"         : 2e-3,\n",
    "    \"epochs\"     : 90,\n",
    "    \"batch_size\" : 64  # Increase if your device can handle it\n",
    "}\n",
    "\n",
    "# You may pass this as a parameter to the dataset class above\n",
    "# This will help modularize your implementation\n",
    "transforms = [] # set of tranformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmuPk9J6L8dz"
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.233571Z",
     "iopub.status.busy": "2024-11-07T05:32:49.233233Z",
     "iopub.status.idle": "2024-11-07T05:32:49.348284Z",
     "shell.execute_reply": "2024-11-07T05:32:49.347285Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.233540Z"
    },
    "id": "3_kG0gU2x4hH",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me RAMMM!!!!\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:32:49.349509Z",
     "iopub.status.busy": "2024-11-07T05:32:49.349202Z",
     "iopub.status.idle": "2024-11-07T05:41:00.645849Z",
     "shell.execute_reply": "2024-11-07T05:41:00.644985Z",
     "shell.execute_reply.started": "2024-11-07T05:32:49.349475Z"
    },
    "id": "4mzoYfTKu14s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root=\"/kaggle/input/11-785-hw3p2-f24/11785-f24-hw3p2\"\n",
    "#TODO: Create a dataset object using the AudioDataset class for the training data\n",
    "train_data = AudioDataset(root=root,audio_transformation=audio_transforms)\n",
    "\n",
    "# TODO: Create a dataset object using the AudioDataset class for the validation data\n",
    "val_data = AudioDataset(root=root, partition=\"dev-clean\")\n",
    "\n",
    "# TODO: Create a dataset object using the AudioTestDataset class for the test data\n",
    "test_data = AudioDatasetTest(root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:00.647498Z",
     "iopub.status.busy": "2024-11-07T05:41:00.647161Z",
     "iopub.status.idle": "2024-11-07T05:41:00.657906Z",
     "shell.execute_reply": "2024-11-07T05:41:00.656971Z",
     "shell.execute_reply.started": "2024-11-07T05:41:00.647463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 28539, batches = 446\n",
      "Val dataset samples = 2703, batches = 43\n",
      "Test dataset samples = 2620, batches = 2620\n"
     ]
    }
   ],
   "source": [
    "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    num_workers = 8,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = True,\n",
    "    collate_fn = train_data.collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    num_workers = 4,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False,\n",
    "    collate_fn = val_data.collate_fn\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = test_data,\n",
    "    num_workers = 4,\n",
    "    batch_size  = 1,\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False,\n",
    "    collate_fn = test_data.collate_fn\n",
    ")\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:00.659516Z",
     "iopub.status.busy": "2024-11-07T05:41:00.659222Z",
     "iopub.status.idle": "2024-11-07T05:41:03.120041Z",
     "shell.execute_reply": "2024-11-07T05:41:03.119080Z",
     "shell.execute_reply.started": "2024-11-07T05:41:00.659485Z"
    },
    "id": "cXMtwyviKaxK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1671, 28]) torch.Size([64, 200]) torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSexxhdfMUzx"
   },
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-qb7wnAzCZl"
   },
   "source": [
    "## ASR Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB6eh3gnMUzy"
   },
   "source": [
    "### Pyramid Bi-LSTM (pBLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.121907Z",
     "iopub.status.busy": "2024-11-07T05:41:03.121555Z",
     "iopub.status.idle": "2024-11-07T05:41:03.126827Z",
     "shell.execute_reply": "2024-11-07T05:41:03.125863Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.121870Z"
    },
    "id": "qd4BEX_yMUzz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils for network\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.129106Z",
     "iopub.status.busy": "2024-11-07T05:41:03.128222Z",
     "iopub.status.idle": "2024-11-07T05:41:03.138229Z",
     "shell.execute_reply": "2024-11-07T05:41:03.137402Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.129072Z"
    },
    "id": "OmdyXI6KMUzz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class pBLSTM(torch.nn.Module):\n",
    "\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
    "\n",
    "    At each step,\n",
    "    1. Pad your input if it is packed (Unpack it)\n",
    "    2. Reduce the input length dimension by concatenating feature dimension\n",
    "        (Tip: Write down the shapes and understand)\n",
    "        (i) How should  you deal with odd/even length input? \n",
    "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
    "    3. Pack your input\n",
    "    4. Pass it into LSTM layer\n",
    "\n",
    "    To make our implementation modular, we pass 1 layer at a time.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(pBLSTM, self).__init__()\n",
    "\n",
    "        self.blstm = nn.LSTM(input_size = 2*input_size, hidden_size = hidden_size, num_layers = 1, bidirectional = True, dropout = 0.2, batch_first = True) \n",
    "\n",
    "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
    "        \n",
    "        x , lengths = pad_packed_sequence(x_packed, batch_first = True)\n",
    "        \n",
    "        x, x_lens = self.trunc_reshape(x, lengths)\n",
    "        \n",
    "        x = pack_padded_sequence(x, x_lens, batch_first = True, enforce_sorted= False)\n",
    "        \n",
    "        x , h= self.blstm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def trunc_reshape(self, x, x_lens): \n",
    "        \n",
    "        if x.shape[1]%2 != 0:\n",
    "            x= x[:,:-1,:]\n",
    "\n",
    "        x = x.reshape(x.shape[0],x.shape[1]//2, x.shape[2]*2)\n",
    "        x_lens  = x_lens//2\n",
    "        return x, x_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3ZQ75OcMUz0"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.139538Z",
     "iopub.status.busy": "2024-11-07T05:41:03.139245Z",
     "iopub.status.idle": "2024-11-07T05:41:03.150965Z",
     "shell.execute_reply": "2024-11-07T05:41:03.150207Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.139501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LockedDropout(nn.Module):\n",
    "    def __init__(self, drop_prob):\n",
    "        super(LockedDropout, self).__init__()\n",
    "        self.prob = drop_prob\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self.prob: # turn it off during inference\n",
    "            return x\n",
    "        x, x_lens = pad_packed_sequence(x, batch_first = True)\n",
    "        m = x.new_empty(x.size(0), 1, x.size(2),requires_grad=False).bernoulli_(1 - self.prob)\n",
    "        mask = m / (1 - self.prob)\n",
    "        mask = mask.expand_as(x)\n",
    "        out = x * mask\n",
    "        out = pack_padded_sequence(out,x_lens, batch_first = True, enforce_sorted= False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.152203Z",
     "iopub.status.busy": "2024-11-07T05:41:03.151942Z",
     "iopub.status.idle": "2024-11-07T05:41:03.167293Z",
     "shell.execute_reply": "2024-11-07T05:41:03.166258Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.152174Z"
    },
    "id": "GEzw5_xmMUz0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Define the Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Define a skip connection if input and output channels differ\n",
    "        self.skip_connection = None\n",
    "        if in_channels != out_channels:\n",
    "            self.skip_connection = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.gelu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Add skip connection\n",
    "        if self.skip_connection is not None:\n",
    "            identity = self.skip_connection(identity)\n",
    "        \n",
    "        out += identity\n",
    "        return F.gelu(out)\n",
    "\n",
    "# Modified Encoder class with Residual Blocks in embed\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Sequential(\n",
    "            PermuteBlock(),\n",
    "            ResidualBlock(input_size, 128),\n",
    "            ResidualBlock(128, 256),\n",
    "            PermuteBlock(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        self.pBLSTMs = nn.Sequential(\n",
    "            pBLSTM(input_size=256, hidden_size=hidden_size),\n",
    "            LockedDropout(0.4),\n",
    "            pBLSTM(input_size=2*hidden_size, hidden_size=hidden_size),\n",
    "            LockedDropout(0.3)\n",
    "        )\n",
    "         \n",
    "    def forward(self, x, lens):\n",
    "        x = self.embed(x)\n",
    "        lens = lens.clamp(max=x.shape[1]).cpu() \n",
    "        x = pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
    "        x = self.pBLSTMs(x)\n",
    "        outputs, lens = pad_packed_sequence(x, batch_first=True)\n",
    "        \n",
    "        return outputs, lens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg82HXa3MUz1"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.168798Z",
     "iopub.status.busy": "2024-11-07T05:41:03.168496Z",
     "iopub.status.idle": "2024-11-07T05:41:03.181323Z",
     "shell.execute_reply": "2024-11-07T05:41:03.180567Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.168765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, output_size= 41):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            PermuteBlock(), torch.nn.BatchNorm1d(embed_size), PermuteBlock(),\n",
    "            #TODO define your MLP arch. Refer HW1P2\n",
    "            #Use Permute Block before and after BatchNorm1d() to match the size\n",
    "            nn.Linear(embed_size, 2048),\n",
    "            nn.GELU(),\n",
    "            PermuteBlock(), torch.nn.BatchNorm1d(2048), PermuteBlock(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.GELU(),\n",
    "            PermuteBlock(), torch.nn.BatchNorm1d(1024), PermuteBlock(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.GELU(),\n",
    "            PermuteBlock(), torch.nn.BatchNorm1d(512), PermuteBlock(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "        \n",
    "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        #TODO call your MLP\n",
    "        #TODO Think what should be the final output of the decoder for the classification \n",
    "        out = self.mlp(encoder_out)\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.182663Z",
     "iopub.status.busy": "2024-11-07T05:41:03.182352Z",
     "iopub.status.idle": "2024-11-07T05:41:03.196080Z",
     "shell.execute_reply": "2024-11-07T05:41:03.195391Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.182621Z"
    },
    "id": "qmHf6pFiMUz1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ASRModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_size= 192, output_size= len(PHONEMES)):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.augmentations  = torch.nn.Sequential(\n",
    "        #     #TODO Add Time Masking/ Frequency Masking\n",
    "        #     #Hint: See how to use PermuteBlock() function defined above\n",
    "        #     PermuteBlock(), \n",
    "        #     torchaudio.transforms.FrequencyMasking(freq_mask_param=10),\n",
    "        #     torchaudio.transforms.TimeMasking(time_mask_param=100),\n",
    "        #     PermuteBlock(),\n",
    "        # ) # did augmentation in the collate_fn\n",
    "        self.encoder        = Encoder(input_size, embed_size)# TODO: Initialize Encoder\n",
    "        self.decoder        = Decoder(embed_size*2, output_size) # TODO: Initialize Decoder \n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self, x, lengths_x):\n",
    "        \n",
    "        # if self.training:\n",
    "        #     x = self.augmentations(x)\n",
    "\n",
    "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
    "        decoder_out                 = self.decoder(encoder_out)\n",
    "\n",
    "        return decoder_out, encoder_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV7DMPDoMUz2"
   },
   "source": [
    "## Initialize ASR Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:03.197449Z",
     "iopub.status.busy": "2024-11-07T05:41:03.197172Z",
     "iopub.status.idle": "2024-11-07T05:41:04.307217Z",
     "shell.execute_reply": "2024-11-07T05:41:04.306094Z",
     "shell.execute_reply.started": "2024-11-07T05:41:03.197418Z"
    },
    "id": "oaaDsnnLMUz2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASRModel(\n",
      "  (encoder): Encoder(\n",
      "    (embed): Sequential(\n",
      "      (0): PermuteBlock()\n",
      "      (1): ResidualBlock(\n",
      "        (conv1): Conv1d(28, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (skip_connection): Conv1d(28, 128, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (skip_connection): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (3): PermuteBlock()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (pBLSTMs): Sequential(\n",
      "      (0): pBLSTM(\n",
      "        (blstm): LSTM(512, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "      )\n",
      "      (1): LockedDropout()\n",
      "      (2): pBLSTM(\n",
      "        (blstm): LSTM(2048, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "      )\n",
      "      (3): LockedDropout()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (mlp): Sequential(\n",
      "      (0): PermuteBlock()\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): PermuteBlock()\n",
      "      (3): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): PermuteBlock()\n",
      "      (6): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): PermuteBlock()\n",
      "      (8): Dropout(p=0.25, inplace=False)\n",
      "      (9): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): PermuteBlock()\n",
      "      (12): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (13): PermuteBlock()\n",
      "      (14): Dropout(p=0.2, inplace=False)\n",
      "      (15): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (16): GELU(approximate='none')\n",
      "      (17): PermuteBlock()\n",
      "      (18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): PermuteBlock()\n",
      "      (20): Dropout(p=0.1, inplace=False)\n",
      "      (21): Linear(in_features=512, out_features=41, bias=True)\n",
      "    )\n",
      "    (softmax): LogSoftmax(dim=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ASRModel(\n",
    "    input_size  = 28,\n",
    "    embed_size  = 512,\n",
    "    output_size = len(PHONEMES)\n",
    ").to(device)\n",
    "print(model)\n",
    "#summary(model, x.to(device), lx.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwunYpyugFg"
   },
   "source": [
    "# Training Config\n",
    "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:04.309062Z",
     "iopub.status.busy": "2024-11-07T05:41:04.308646Z",
     "iopub.status.idle": "2024-11-07T05:41:04.316277Z",
     "shell.execute_reply": "2024-11-07T05:41:04.315364Z",
     "shell.execute_reply.started": "2024-11-07T05:41:04.309018Z"
    },
    "id": "iGoozH2nd6KB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "\n",
    "criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False) # Define CTC loss as the criterion. How would the losses be reduced?\n",
    "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
    "# Refer to the handout for hints\n",
    "\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr= config['lr']) # What goes in here?\n",
    "\n",
    "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
    "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
    "decoder = CTCBeamDecoder(LABELS, beam_width =config['beam_width'], log_probs_input = True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.6,patience=1)\n",
    "\n",
    "# Mixed Precision, if you need it\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmc6_4eWL2Xp"
   },
   "source": [
    "# Decode Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:04.317644Z",
     "iopub.status.busy": "2024-11-07T05:41:04.317294Z",
     "iopub.status.idle": "2024-11-07T05:41:04.327593Z",
     "shell.execute_reply": "2024-11-07T05:41:04.326789Z",
     "shell.execute_reply.started": "2024-11-07T05:41:04.317612Z"
    },
    "id": "KHjnCDddL36E",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
    "    \n",
    "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
    "    beam_results, beam_scores, timesteps, out_seq_len = decoder.decode(output,seq_lens=output_lens) #lengths - list of lengths\n",
    "\n",
    "    pred_strings  = []\n",
    "    # print(beam_results.shape)\n",
    "    # print(beam_results)\n",
    "    for i in range(output_lens.shape[0]):\n",
    "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
    "        pred_strings.append(''.join([PHONEME_MAP[n] for n in beam_results[i][0][:out_seq_len[i][0]]]))\n",
    "    # print(pred_strings)\n",
    "    \n",
    "    return pred_strings\n",
    "\n",
    "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
    "    \n",
    "    dist            = 0\n",
    "    batch_size      = label.shape[0]\n",
    "\n",
    "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
    "    # print(batch_size)\n",
    "    for i in range(batch_size):\n",
    "        # TODO: Get predicted string and label string for each element in the batch\n",
    "        pred_string = pred_strings[i]#TODO\n",
    "        # print('pred',pred_string)\n",
    "        label_string = ''.join([PHONEME_MAP[n] for n in label[i][:label_lens[i]]]) #TODO\n",
    "        # print('label',label_string)\n",
    "        dist += Levenshtein.distance(pred_string, label_string)\n",
    "\n",
    "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qk9iZud1LXT"
   },
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:04.328989Z",
     "iopub.status.busy": "2024-11-07T05:41:04.328667Z",
     "iopub.status.idle": "2024-11-07T05:41:06.181356Z",
     "shell.execute_reply": "2024-11-07T05:41:06.180217Z",
     "shell.execute_reply.started": "2024-11-07T05:41:04.328953Z"
    },
    "id": "GnTLL-5gMBrY",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 734, 41])\n",
      "torch.Size([734, 64, 41]) torch.Size([64, 265])\n",
      "tensor(7.6873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "62.28125\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    x, y, lx, ly = data\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h, lh = model(x, lx)\n",
    "    print(h.shape)\n",
    "    h = torch.permute(h, (1, 0, 2))\n",
    "    print(h.shape, y.shape)\n",
    "    loss = criterion(h, y, lh, ly)\n",
    "    print(loss)\n",
    "    print(calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd5aNaLVoR_g"
   },
   "source": [
    "# WandB\n",
    "\n",
    "You will need to fetch your api key from wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:06.183188Z",
     "iopub.status.busy": "2024-11-07T05:41:06.182817Z",
     "iopub.status.idle": "2024-11-07T05:41:08.648149Z",
     "shell.execute_reply": "2024-11-07T05:41:08.646985Z",
     "shell.execute_reply.started": "2024-11-07T05:41:06.183153Z"
    },
    "id": "PiDduMaDIARE",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"d55e83a86cb97a0c3653945cccd0eed009d488a1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:08.650086Z",
     "iopub.status.busy": "2024-11-07T05:41:08.649436Z",
     "iopub.status.idle": "2024-11-07T05:41:11.842606Z",
     "shell.execute_reply": "2024-11-07T05:41:11.841625Z",
     "shell.execute_reply.started": "2024-11-07T05:41:08.650039Z"
    },
    "id": "4s52yBOvICPZ",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshunl\u001b[0m (\u001b[33mshunl-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3396affed2584981b733dfe40457eac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113000255555663, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241107_054108-xm79rrl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations/runs/xm79rrl1' target=\"_blank\">early-submission</a></strong> to <a href='https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations' target=\"_blank\">https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations/runs/xm79rrl1' target=\"_blank\">https://wandb.ai/shunl-carnegie-mellon-university/hw3p2-ablations/runs/xm79rrl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    name = \"early-submission\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account\n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fLLj5KIMMOe"
   },
   "source": [
    "# Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:11.844112Z",
     "iopub.status.busy": "2024-11-07T05:41:11.843813Z",
     "iopub.status.idle": "2024-11-07T05:41:11.860405Z",
     "shell.execute_reply": "2024-11-07T05:41:11.859437Z",
     "shell.execute_reply.started": "2024-11-07T05:41:11.844080Z"
    },
    "id": "ri87MAdhMUz5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h, y, lh, ly)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "\n",
    "        # Another couple things you need for FP16.\n",
    "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        scaler.update() # This is something added just for FP16\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
    "\n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    total_loss = 0\n",
    "    vdist = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader):\n",
    "\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h, y, lh, ly)\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    total_loss = total_loss/len(val_loader)\n",
    "    val_dist = vdist/len(val_loader)\n",
    "    return total_loss, val_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpYExu4vT4_g"
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:11.861978Z",
     "iopub.status.busy": "2024-11-07T05:41:11.861664Z",
     "iopub.status.idle": "2024-11-07T05:41:11.874713Z",
     "shell.execute_reply": "2024-11-07T05:41:11.873797Z",
     "shell.execute_reply.started": "2024-11-07T05:41:11.861944Z"
    },
    "id": "husa5_EYMUz6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, metric, epoch,path):\n",
    "    torch.save(\n",
    "        {'model_state_dict'         : model.state_dict(),\n",
    "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
    "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
    "         metric[0]                  : metric[1],\n",
    "         'epoch'                    : epoch},\n",
    "        path\n",
    "    )\n",
    "\n",
    "def load_model(path, model, optimizer= None, scheduler= None):\n",
    "\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:11.880987Z",
     "iopub.status.busy": "2024-11-07T05:41:11.880667Z",
     "iopub.status.idle": "2024-11-07T05:41:11.886379Z",
     "shell.execute_reply": "2024-11-07T05:41:11.885334Z",
     "shell.execute_reply.started": "2024-11-07T05:41:11.880955Z"
    },
    "id": "tExvyl1BIdMC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is for checkpointing, if you're doing it over multiple sessions\n",
    "\n",
    "last_epoch_completed = 0\n",
    "start = last_epoch_completed\n",
    "end = config[\"epochs\"]\n",
    "best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:41:11.888088Z",
     "iopub.status.busy": "2024-11-07T05:41:11.887625Z",
     "iopub.status.idle": "2024-11-07T13:36:33.670829Z",
     "shell.execute_reply": "2024-11-07T13:36:33.668894Z",
     "shell.execute_reply.started": "2024-11-07T05:41:11.888055Z"
    },
    "id": "JR43E28rM9Ak",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 1.9622\t Learning Rate 0.0020000\n",
      "\tVal Dist 22.5260%\t Val Loss 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model\n",
      "\n",
      "Epoch: 2/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 1.0011\t Learning Rate 0.0020000\n",
      "\tVal Dist 16.1877%\t Val Loss 0.6751\n",
      "Saved best model\n",
      "\n",
      "Epoch: 3/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.8087\t Learning Rate 0.0020000\n",
      "\tVal Dist 13.2817%\t Val Loss 0.5526\n",
      "Saved best model\n",
      "\n",
      "Epoch: 4/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.7088\t Learning Rate 0.0020000\n",
      "\tVal Dist 11.8758%\t Val Loss 0.4843\n",
      "Saved best model\n",
      "\n",
      "Epoch: 5/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.6185\t Learning Rate 0.0020000\n",
      "\tVal Dist 10.3601%\t Val Loss 0.4248\n",
      "Saved best model\n",
      "\n",
      "Epoch: 6/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.5551\t Learning Rate 0.0020000\n",
      "\tVal Dist 9.8703%\t Val Loss 0.4029\n",
      "Saved best model\n",
      "\n",
      "Epoch: 7/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.5331\t Learning Rate 0.0020000\n",
      "\tVal Dist 9.4980%\t Val Loss 0.3879\n",
      "Saved best model\n",
      "\n",
      "Epoch: 8/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.5123\t Learning Rate 0.0020000\n",
      "\tVal Dist 9.1482%\t Val Loss 0.3714\n",
      "Saved best model\n",
      "\n",
      "Epoch: 9/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4985\t Learning Rate 0.0020000\n",
      "\tVal Dist 8.7581%\t Val Loss 0.3591\n",
      "Saved best model\n",
      "\n",
      "Epoch: 10/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4573\t Learning Rate 0.0020000\n",
      "\tVal Dist 8.2270%\t Val Loss 0.3368\n",
      "Saved best model\n",
      "\n",
      "Epoch: 11/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4450\t Learning Rate 0.0020000\n",
      "\tVal Dist 8.1904%\t Val Loss 0.3334\n",
      "Saved best model\n",
      "\n",
      "Epoch: 12/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4309\t Learning Rate 0.0020000\n",
      "\tVal Dist 8.0083%\t Val Loss 0.3265\n",
      "Saved best model\n",
      "\n",
      "Epoch: 13/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4255\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.8544%\t Val Loss 0.3200\n",
      "Saved best model\n",
      "\n",
      "Epoch: 14/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4115\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.5769%\t Val Loss 0.3088\n",
      "Saved best model\n",
      "\n",
      "Epoch: 15/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3958\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.5453%\t Val Loss 0.3111\n",
      "Saved best model\n",
      "\n",
      "Epoch: 16/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3807\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.4013%\t Val Loss 0.3020\n",
      "Saved best model\n",
      "\n",
      "Epoch: 17/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3893\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.5903%\t Val Loss 0.3097\n",
      "\n",
      "Epoch: 18/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4111\t Learning Rate 0.0020000\n",
      "\tVal Dist 7.5931%\t Val Loss 0.3097\n",
      "\n",
      "Epoch: 19/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3859\t Learning Rate 0.0012000\n",
      "\tVal Dist 7.3071%\t Val Loss 0.2975\n",
      "Saved best model\n",
      "\n",
      "Epoch: 20/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3775\t Learning Rate 0.0012000\n",
      "\tVal Dist 7.2038%\t Val Loss 0.2942\n",
      "Saved best model\n",
      "\n",
      "Epoch: 21/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3667\t Learning Rate 0.0012000\n",
      "\tVal Dist 7.0859%\t Val Loss 0.2911\n",
      "Saved best model\n",
      "\n",
      "Epoch: 22/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3610\t Learning Rate 0.0012000\n",
      "\tVal Dist 6.9880%\t Val Loss 0.2857\n",
      "Saved best model\n",
      "\n",
      "Epoch: 23/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3588\t Learning Rate 0.0012000\n",
      "\tVal Dist 6.9598%\t Val Loss 0.2827\n",
      "Saved best model\n",
      "\n",
      "Epoch: 24/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3440\t Learning Rate 0.0012000\n",
      "\tVal Dist 7.1317%\t Val Loss 0.2916\n",
      "\n",
      "Epoch: 25/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3592\t Learning Rate 0.0012000\n",
      "\tVal Dist 7.0304%\t Val Loss 0.2905\n",
      "\n",
      "Epoch: 26/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3537\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.8642%\t Val Loss 0.2843\n",
      "Saved best model\n",
      "\n",
      "Epoch: 27/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3362\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.8247%\t Val Loss 0.2825\n",
      "Saved best model\n",
      "\n",
      "Epoch: 28/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3407\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.7447%\t Val Loss 0.2780\n",
      "Saved best model\n",
      "\n",
      "Epoch: 29/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3347\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.6885%\t Val Loss 0.2768\n",
      "Saved best model\n",
      "\n",
      "Epoch: 30/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3285\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.7787%\t Val Loss 0.2800\n",
      "\n",
      "Epoch: 31/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3362\t Learning Rate 0.0007200\n",
      "\tVal Dist 6.7641%\t Val Loss 0.2796\n",
      "\n",
      "Epoch: 32/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3223\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.6084%\t Val Loss 0.2737\n",
      "Saved best model\n",
      "\n",
      "Epoch: 33/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3298\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5871%\t Val Loss 0.2723\n",
      "Saved best model\n",
      "\n",
      "Epoch: 34/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3146\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5856%\t Val Loss 0.2720\n",
      "Saved best model\n",
      "\n",
      "Epoch: 35/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3170\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5933%\t Val Loss 0.2751\n",
      "\n",
      "Epoch: 36/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3099\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5508%\t Val Loss 0.2735\n",
      "Saved best model\n",
      "\n",
      "Epoch: 37/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3170\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.4961%\t Val Loss 0.2713\n",
      "Saved best model\n",
      "\n",
      "Epoch: 38/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3106\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5360%\t Val Loss 0.2707\n",
      "\n",
      "Epoch: 39/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3110\t Learning Rate 0.0004320\n",
      "\tVal Dist 6.5057%\t Val Loss 0.2709\n",
      "\n",
      "Epoch: 40/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3111\t Learning Rate 0.0002592\n",
      "\tVal Dist 6.4233%\t Val Loss 0.2668\n",
      "Saved best model\n",
      "\n",
      "Epoch: 41/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3024\t Learning Rate 0.0002592\n",
      "\tVal Dist 6.4833%\t Val Loss 0.2720\n",
      "\n",
      "Epoch: 42/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3026\t Learning Rate 0.0002592\n",
      "\tVal Dist 6.4348%\t Val Loss 0.2686\n",
      "\n",
      "Epoch: 43/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3015\t Learning Rate 0.0001555\n",
      "\tVal Dist 6.3744%\t Val Loss 0.2662\n",
      "Saved best model\n",
      "\n",
      "Epoch: 44/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2989\t Learning Rate 0.0001555\n",
      "\tVal Dist 6.3698%\t Val Loss 0.2660\n",
      "Saved best model\n",
      "\n",
      "Epoch: 45/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3095\t Learning Rate 0.0001555\n",
      "\tVal Dist 6.3838%\t Val Loss 0.2658\n",
      "\n",
      "Epoch: 46/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3046\t Learning Rate 0.0001555\n",
      "\tVal Dist 6.3925%\t Val Loss 0.2675\n",
      "\n",
      "Epoch: 47/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3027\t Learning Rate 0.0000933\n",
      "\tVal Dist 6.3433%\t Val Loss 0.2644\n",
      "Saved best model\n",
      "\n",
      "Epoch: 48/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3066\t Learning Rate 0.0000933\n",
      "\tVal Dist 6.4061%\t Val Loss 0.2693\n",
      "\n",
      "Epoch: 49/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2915\t Learning Rate 0.0000933\n",
      "\tVal Dist 6.3433%\t Val Loss 0.2661\n",
      "\n",
      "Epoch: 50/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2871\t Learning Rate 0.0000560\n",
      "\tVal Dist 6.3515%\t Val Loss 0.2668\n",
      "\n",
      "Epoch: 51/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2938\t Learning Rate 0.0000560\n",
      "\tVal Dist 6.3311%\t Val Loss 0.2660\n",
      "Saved best model\n",
      "\n",
      "Epoch: 52/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2952\t Learning Rate 0.0000560\n",
      "\tVal Dist 6.3377%\t Val Loss 0.2654\n",
      "\n",
      "Epoch: 53/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2916\t Learning Rate 0.0000560\n",
      "\tVal Dist 6.3280%\t Val Loss 0.2654\n",
      "Saved best model\n",
      "\n",
      "Epoch: 54/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  74%|███████▍  | 329/446 [06:12<02:09,  1.11s/it, loss=0.2984, lr=0.000056]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     10\u001b[0m curr_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m train_loss              \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m valid_loss, valid_dist  \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, decoder, phoneme_map\u001b[38;5;241m=\u001b[39m LABELS)\n\u001b[1;32m     14\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(valid_dist)\n",
      "Cell \u001b[0;32mIn[26], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m batch_bar\u001b[38;5;241m.\u001b[39mupdate() \u001b[38;5;66;03m# Update tqdm bar\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Another couple things you need for FP16.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This is a replacement for loss.backward()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     32\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer) \u001b[38;5;66;03m# This is a replacement for optimizer.step()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#TODO: Please complete the training loop\n",
    "\n",
    "for epoch in range(0, config['epochs']):\n",
    "\n",
    "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    train_loss              = train_model(model, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)\n",
    "    scheduler.step(valid_dist)\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
    "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
    "\n",
    "\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'valid_dist': valid_dist,\n",
    "        'valid_loss': valid_loss,\n",
    "        'lr'        : curr_lr\n",
    "    })\n",
    "    '''\n",
    "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch)\n",
    "    wandb.save(epoch_model_path)\n",
    "    print(\"Saved epoch model\")\n",
    "    '''\n",
    "\n",
    "    if valid_dist <= best_lev_dist:\n",
    "        best_lev_dist = valid_dist\n",
    "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, '/kaggle/working/best_ret.pth')\n",
    "        wandb.save('/kaggle/working/best_ret.pth')\n",
    "        print(\"Saved best model\")\n",
    "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.672080Z",
     "iopub.status.idle": "2024-11-07T13:36:33.672494Z",
     "shell.execute_reply": "2024-11-07T13:36:33.672314Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.672293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder = CTCBeamDecoder(LABELS, beam_width =30, log_probs_input = True)\n",
    "valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)\n",
    "print(valid_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.674052Z",
     "iopub.status.idle": "2024-11-07T13:36:33.674599Z",
     "shell.execute_reply": "2024-11-07T13:36:33.674336Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.674307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder = CTCBeamDecoder(LABELS, beam_width =1, log_probs_input = True)\n",
    "valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)\n",
    "print(valid_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.676481Z",
     "iopub.status.idle": "2024-11-07T13:36:33.677007Z",
     "shell.execute_reply": "2024-11-07T13:36:33.676747Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.676721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder = CTCBeamDecoder(LABELS, beam_width =40, log_probs_input = True)\n",
    "valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)\n",
    "print(valid_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.678450Z",
     "iopub.status.idle": "2024-11-07T13:36:33.678989Z",
     "shell.execute_reply": "2024-11-07T13:36:33.678718Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.678691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder = CTCBeamDecoder(LABELS, beam_width =3, log_probs_input = True)\n",
    "valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)\n",
    "print(valid_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.680618Z",
     "iopub.status.idle": "2024-11-07T13:36:33.681202Z",
     "shell.execute_reply": "2024-11-07T13:36:33.680964Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.680918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model=load_model('/kaggle/working/best_ret.pth', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2H4EEj-sD32"
   },
   "source": [
    "# Generate Predictions and Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.684052Z",
     "iopub.status.idle": "2024-11-07T13:36:33.685083Z",
     "shell.execute_reply": "2024-11-07T13:36:33.684796Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.684767Z"
    },
    "id": "2moYJhTWsOG-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#TODO: Make predictions\n",
    "\n",
    "# Follow the steps below:\n",
    "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
    "# 2. Get prediction string by decoding the results of the beam decoder\n",
    "\n",
    "TEST_BEAM_WIDTH = 200\n",
    "\n",
    "test_decoder = CTCBeamDecoder(LABELS, beam_width =TEST_BEAM_WIDTH, log_probs_input = True)\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "print(\"Testing\")\n",
    "for data in tqdm(test_loader):\n",
    "\n",
    "    x, lx   = data\n",
    "    x       = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h, lh = model(x, lx)\n",
    "\n",
    "    prediction_string= decode_prediction(h,lh, test_decoder, LABELS)\n",
    "    \n",
    "    results.extend(prediction_string)\n",
    "    \n",
    "    del x, lx, h, lh\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.686525Z",
     "iopub.status.idle": "2024-11-07T13:36:33.687493Z",
     "shell.execute_reply": "2024-11-07T13:36:33.687223Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.687192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.689007Z",
     "iopub.status.idle": "2024-11-07T13:36:33.689977Z",
     "shell.execute_reply": "2024-11-07T13:36:33.689704Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.689675Z"
    },
    "id": "d70dvu_lsMlv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = f\"/kaggle/input/example/random_submission.csv\"\n",
    "df = pd.read_csv(data_dir)\n",
    "df.label = results\n",
    "df.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-07T13:36:33.691085Z",
     "iopub.status.idle": "2024-11-07T13:36:33.691568Z",
     "shell.execute_reply": "2024-11-07T13:36:33.691339Z",
     "shell.execute_reply.started": "2024-11-07T13:36:33.691315Z"
    },
    "id": "m1sZmEIs4yIz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c hw3p2-785-f24 -f submission.csv -m \"I made it!\"\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rd5aNaLVoR_g"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9982962,
     "sourceId": 87560,
     "sourceType": "competition"
    },
    {
     "datasetId": 5975375,
     "sourceId": 9758432,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
